{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions \n",
    "using IntervalSets\n",
    "using ValueShapes\n",
    "using ArraysOfArrays\n",
    "using StatsBase \n",
    "using LinearAlgebra\n",
    "using Random123\n",
    "using HCubature\n",
    "using LaTeXStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plots\n",
    "import PyPlot\n",
    "Plots.pyplot()\n",
    "\n",
    "plt = PyPlot\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 11\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc(\"font\", size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "colors = vcat([0 0 0 0], plt.cm.YlOrRd(range(0, stop=1, length=10))[2:end,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using BATPar\n",
    "using KDTree\n",
    "using BAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # simple Normal Distribution: \n",
    "\n",
    "# N = 5\n",
    "# min_v = -6.\n",
    "# max_v = 6.\n",
    "\n",
    "# lgV = N*log(max_v-min_v); \n",
    "\n",
    "# f(x::AbstractArray) = prod(pdf.(Normal(0, 1), x))\n",
    "\n",
    "# LogTrueIntegral(N)=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple Normal Distribution: \n",
    "\n",
    "N = 5\n",
    "min_v = -10.\n",
    "max_v = 10.\n",
    "\n",
    "dist_dim = truncated(Normal(0,1), min_v, max_v)\n",
    "dist = product_distribution([dist_dim for i in 1:N])\n",
    "\n",
    "f(x::AbstractArray) = pdf(dist, x)\n",
    "\n",
    "lgV = N*log(max_v-min_v); \n",
    "\n",
    "LogTrueIntegral(N)=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = params -> LogDVal((log(f(params.a))))\n",
    "prior = NamedTupleDist(a = [[min_v .. max_v for i in 1:N]...],)\n",
    "posterior = PosteriorDensity(likelihood, prior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnsamples = 10^2\n",
    "nnchains = 5\n",
    "\n",
    "samples, stats = bat_sample(posterior, (nnsamples, nnchains), MetropolisHastings());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = flatview(unshaped.(samples.v))\n",
    "weights_LogLik = samples.logd\n",
    "weights_Histogram = samples.weight;\n",
    "\n",
    "data_kdtree = Data(smpl[:,1:end], weights_Histogram[1:end], weights_LogLik[1:end]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Partitioning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDTree.evaluate_total_cost(data::Data) = KDTree.cost_f_1(data)\n",
    "\n",
    "output, cost_array = DefineKDTree(data_kdtree, collect(1:N), 10);\n",
    "\n",
    "extend_tree_bounds!(output, repeat([min_v], N), repeat([max_v], N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_bounds = [min_v, max_v] \n",
    "\n",
    "extend_tree_bounds!(output, repeat([prior_bounds[1]], N), repeat([prior_bounds[2]], N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "ax.scatter(smpl[1,:], smpl[2,:], color=\"k\", s=0.4)\n",
    "ax.set_xlabel(L\"\\lambda_1\")\n",
    "ax.set_ylabel(L\"\\lambda_2\")\n",
    "\n",
    "plot_tree(output, [1,2], ax, color=\"red\")\n",
    "\n",
    "# ax.set_xlim(-11., 11.)\n",
    "# ax.set_ylim(-11., 11.)\n",
    "\n",
    "# ax.set_xlim(-4., 4.)\n",
    "# ax.set_ylim(-4., 4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling of subspaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = MCMCBurninStrategy(\n",
    "    max_nsamples_per_cycle = 5000,\n",
    "    max_nsteps_per_cycle = 50000,\n",
    "    max_time_per_cycle = Inf,\n",
    "    max_ncycles = 150\n",
    ")\n",
    "\n",
    "tuning = AdaptiveMetropolisTuning(\n",
    "    λ = 0.5,\n",
    "    α = 0.05..0.15,\n",
    "    β = 1.5,\n",
    "    c = 1e-4..1e2\n",
    ")\n",
    "\n",
    "\n",
    "AHMI_settingss = BAT.HMISettings(BAT.cholesky_partial_whitening!,\n",
    "    10000, 2.5, 0.1, true, 16, true, Dict(\"cov. weighted result\" => BAT.hm_combineresults_covweighted!)\n",
    ")\n",
    "\n",
    "algorithm = MetropolisHastings(ARPWeighting())\n",
    "\n",
    "nnchains = 3\n",
    "nnsamples = 10^4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_part = extract_par_bounds(output)\n",
    "BATPar.make_named_prior(i) = BAT.NamedTupleDist( a =  [[i[j,1]..i[j,2] for j in 1:size(i)[1]]...])\n",
    "algorithm = MetropolisHastings();\n",
    "\n",
    "samples_parallel = bat_sample_parallel(likelihood, bounds_part, (nnsamples, nnchains), algorithm, tuning=tuning, burnin=burnin, settings=AHMI_settingss); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_par = hcat(samples_parallel.samples...)\n",
    "x = smpl_par[1,:]\n",
    "y = smpl_par[2,:]\n",
    "w_o = samples_parallel.weights_o\n",
    "w_r =  samples_parallel.weights_r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show \"Truth\", exp(LogTrueIntegral(N))\n",
    "\n",
    "@show \"Int\", sum(samples_parallel.integrals), sqrt(sum((samples_parallel.uncertainty).^2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_range = range(min_v, stop=max_v, length=50)\n",
    "\n",
    "histogram_wr = fit(Histogram, (x, y), weights(w_r), nbins=100)\n",
    "histogram_wo = fit(Histogram, (x, y), weights(w_o), nbins=100)\n",
    "histogram_wr = normalize(histogram_wr, mode=:pdf);\n",
    "histogram_wo = normalize(histogram_wo, mode=:pdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax[1].pcolormesh(midpoints(histogram_wr.edges[1]), midpoints(histogram_wr.edges[2]), replace(histogram_wr.weights', 0=>NaN), cmap=\"RdYlBu_r\") \n",
    "ax[3].pcolormesh(midpoints(histogram_wr.edges[1]), midpoints(histogram_wr.edges[2]), replace(histogram_wr.weights', 0=>NaN), cmap=\"RdYlBu_r\") \n",
    "ax[2].pcolormesh(midpoints(histogram_wo.edges[1]), midpoints(histogram_wo.edges[2]), replace(histogram_wo.weights', 0=>NaN), cmap=\"RdYlBu_r\") \n",
    "\n",
    "plot_tree(output, [1,2], ax[2], linewidth=0.8, color=\"black\", alpha=0.4)\n",
    "\n",
    "ax[1].set_xlabel(L\"\\lambda_1\")\n",
    "ax[1].set_ylabel(L\"\\lambda_2\")\n",
    "\n",
    "ax[1].set_xlim(min_v, max_v)\n",
    "ax[1].set_ylim(min_v, max_v)\n",
    "\n",
    "ax[3].set_xlabel(L\"\\lambda_1\")\n",
    "ax[3].get_yaxis().set_visible(false)\n",
    "ax[2].get_yaxis().set_visible(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underestimation/bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cuts = 3\n",
    "n_smpl_cut = 10^4\n",
    "n_chains = 10\n",
    "\n",
    "AHMI_settings = BAT.HMISettings(BAT.cholesky_partial_whitening!,\n",
    "    1000, 1.0, 0.1, true, 16, true, Dict(\"cov. weighted result\" => BAT.hm_combineresults_covweighted!)\n",
    ")\n",
    "\n",
    "algorithm = MetropolisHastings()\n",
    "\n",
    "burnin = BAT.MCMCBurninStrategy()\n",
    "\n",
    "tuning = AdaptiveMetropolisTuning(\n",
    "    λ = 0.5,\n",
    "    α = 0.15..0.2,\n",
    "    β = 1.5,\n",
    "    c = 1e-4..1e2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_data(n_runs, n_cuts, n_smpl_cut, n_chains; AHMI_settings=AHMI_settings)\n",
    "    \n",
    "    integrals_true = Vector{Float64}()\n",
    "    log_v_true = Vector{Float64}()\n",
    "    \n",
    "    integrals_partsmpl = Vector{Float64}()\n",
    "    uns_partsmpl = Vector{Float64}()\n",
    "    log_v_part = Vector{Float64}()\n",
    "    \n",
    "    integrals_ahmi = Vector{Float64}()\n",
    "    uns_ahmi = Vector{Float64}()\n",
    "    \n",
    "    for i in 1:n_runs\n",
    "        \n",
    "        @show i \n",
    "        \n",
    "        seeds, stats = bat_sample(posterior, (100, 10), MetropolisHastings())\n",
    "        kd_data = Data(flatview(unshaped.(seeds.v))[:,1:end], seeds.weight[1:end], seeds.logd[1:end])\n",
    "        kd_output, _ = DefineKDTree(kd_data, collect(1:N), n_cuts);\n",
    "        extend_tree_bounds!(kd_output, repeat([min_v], N), repeat([max_v], N)) # try changing this \n",
    "        kd_bounds = extract_par_bounds(kd_output)\n",
    "        samples_par = bat_sample_parallel(likelihood, kd_bounds, (n_smpl_cut, n_chains), algorithm, tuning=tuning, burnin=burnin, settings=AHMI_settings);\n",
    "        par_integral_run = [sum(samples_par.integrals), sqrt(sum((samples_par.uncertainty).^2))] ./ 1.0\n",
    "        \n",
    "        tot_volum = sum([prod(diff(j, dims=2)) for j in kd_bounds])\n",
    "        \n",
    "        # ***\n",
    "        \n",
    "        samples_serial, stats_serial = bat_sample(posterior, ((1+n_cuts)*n_smpl_cut, n_chains), MetropolisHastings(), tuning=tuning, burnin=burnin,)\n",
    "        hmi_data = BAT.HMIData(unshaped.(samples_serial))\n",
    "        BAT.hm_integrate!(hmi_data, settings=AHMI_settings)\n",
    "        \n",
    "        ahmi_integral_run =[hmi_data.integralestimates[\"cov. weighted result\"].final.estimate, hmi_data.integralestimates[\"cov. weighted result\"].final.uncertainty]\n",
    "\t\t\n",
    "        log_smpl_int = ahmi_integral_run .* exp(lgV)\n",
    "        \n",
    "        # ***\n",
    "        \n",
    "        push!(integrals_true, 0.0)\n",
    "        push!(integrals_partsmpl, par_integral_run[1])\n",
    "        push!(uns_partsmpl, par_integral_run[2])\n",
    "        push!(integrals_ahmi, log_smpl_int[1])\n",
    "        push!(uns_ahmi, log_smpl_int[2])\n",
    "        push!(log_v_true, lgV)\n",
    "        push!(log_v_part, tot_volum)\n",
    "    end\n",
    "    \n",
    "    return (integrals_true, log_v_true, integrals_partsmpl, uns_partsmpl, log_v_part, integrals_ahmi, uns_ahmi)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(int_true, lgV_true, int_part, uns_part, lgV_part, int_ahmi, uns_ahmi) = generate_data(30, n_cuts, n_smpl_cut, n_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrals_partition = int_part\n",
    "integral_ahmi = int_ahmi\n",
    "integrals_true = ones(length(integral_ahmi))\n",
    "\n",
    "unsert_partition = uns_part\n",
    "unsert_ahmi = uns_ahmi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "\n",
    "ax.axvline(1, c=\"red\", label=\"Truth\", alpha=0.5)\n",
    "ax.axvline(mean(integrals_partition), c=\"C0\", alpha=0.5)\n",
    "ax.axvline(mean(integral_ahmi), c=\"C1\", alpha=0.5)\n",
    "\n",
    "ax.hist(integrals_partition, bins=10, density=true, color=\"C0\", alpha=0.5, label=\"w/ partition\")\n",
    "ax.hist(integral_ahmi, bins=10, density=true, color=\"C1\", alpha=0.5, label=\"w/o partition\")\n",
    "\n",
    "ax.legend(loc=\"upper left\", frameon=true, framealpha=0.8, ncol=1)\n",
    "\n",
    "ax.set_xlim(0.95, 1.05)\n",
    "\n",
    "ax.set_xlabel(\"I\")\n",
    "ax.set_ylabel(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "\n",
    "ax.axvline(1, c=\"red\", label=\"Truth\", alpha=0.5)\n",
    "ax.axvline(mean(integrals_partition), c=\"C0\", alpha=0.5)\n",
    "\n",
    "ax.hist(integrals_partition, bins=10, density=true, color=\"C0\", alpha=0.5, label=\"w/ partition\")\n",
    "ax.legend(loc=\"upper left\", frameon=true, framealpha=0.8, ncol=1)\n",
    "\n",
    "ax.set_xlim(0.95, 1.05)\n",
    "\n",
    "ax.set_xlabel(\"I\")\n",
    "ax.set_ylabel(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0-rc1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
